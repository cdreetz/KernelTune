# Resources


- (KernelBook)[https://huggingface.co/datasets/GPUMODE/KernelBook] is a curated collection of pairs of pytorch programs and equivalent triton code (generated by torch inductor) 
- (KernelBench)[https://huggingface.co/datasets/ScalingIntelligence/KernelBench] A benchmark designed to evaluate the ability of LLMs to generate efficient GPU kernels for optimizing neural network performance
- (ComputeEval)[https://github.com/nvidia/compute-eval] ComputeEval: Evaluating Large Language Models for CUDA Code Generation

- (Kevin-32B)[https://cognition.ai/blog/kevin-32b] Kevin-32B: Multi-Turn RL for Writing CUDA Kernels
- (KernelLLM)[https://huggingface.co/facebook/KernelLLM] a large language model based on Llama 3.1 Instruct, which has been trained specifically for the task of authoring GPU kernels using Triton.

- (Kwen0.1)[https://huggingface.co/cdreetz/kwen2.5-1.5b] Qwen finetuned to write triton kernels
- (KwenSFTDataset)[https://huggingface.co/datasets/cdreetz/triton-sft-dataset] corresponding dataset used to train Kwen

